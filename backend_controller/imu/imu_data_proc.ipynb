{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports And Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import butter, filtfilt\n",
    "import json\n",
    "import mysql.connector\n",
    "import ast\n",
    "\n",
    "db_config = {\n",
    "    'host': '150.140.186.118',\n",
    "    'port': 3306,\n",
    "    'user': 'readonly_student',\n",
    "    'password': 'iot_password',\n",
    "    'database': 'default'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(table_name, attr_name, start_datetime=None, end_datetime=None):\n",
    "    \n",
    "    try:\n",
    "        # Establish the connection to the database\n",
    "        connection = mysql.connector.connect(**db_config)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        query = f\"\"\"\n",
    "            SELECT \n",
    "                R1.attrValue AS timestamp,\n",
    "                R2.attrValue AS location, \n",
    "                R4.attrValue AS acc_x, \n",
    "                R5.attrValue AS acc_y, \n",
    "                R6.attrValue AS acc_z,\n",
    "                R7.attrValue AS speed,\n",
    "                R8.attrValue AS altitude\n",
    "            FROM \n",
    "                `default`.AutoSenseAnalytics_IMU_Measurement_raw AS R1 \n",
    "            JOIN \n",
    "                `default`.AutoSenseAnalytics_IMU_Measurement_raw AS R2 \n",
    "            JOIN \n",
    "                `default`.AutoSenseAnalytics_IMU_Measurement_raw AS R4 \n",
    "            JOIN \n",
    "                `default`.AutoSenseAnalytics_IMU_Measurement_raw AS R5  \n",
    "            JOIN \n",
    "                `default`.AutoSenseAnalytics_IMU_Measurement_raw AS R6\n",
    "            JOIN \n",
    "                `default`.AutoSenseAnalytics_IMU_Measurement_raw AS R7\n",
    "            JOIN \n",
    "                `default`.AutoSenseAnalytics_IMU_Measurement_raw AS R8\n",
    "            ON \n",
    "                R1.recvTimeTs = R2.recvTimeTs AND\n",
    "                R1.recvTimeTs = R4.recvTimeTs AND\n",
    "                R1.recvTimeTs = R5.recvTimeTs AND\n",
    "                R1.recvTimeTs = R6.recvTimeTs AND\n",
    "                R1.recvTimeTs = R7.recvTimeTs AND\n",
    "                R1.recvTimeTs = R8.recvTimeTs AND\n",
    "                R2.recvTimeTs = R4.recvTimeTs AND\n",
    "                R2.recvTimeTs = R5.recvTimeTs AND\n",
    "                R2.recvTimeTs = R6.recvTimeTs AND\n",
    "                R2.recvTimeTs = R7.recvTimeTs AND\n",
    "                R2.recvTimeTs = R8.recvTimeTs AND\n",
    "                R4.recvTimeTs = R5.recvTimeTs AND\n",
    "                R4.recvTimeTs = R6.recvTimeTs AND\n",
    "                R4.recvTimeTs = R7.recvTimeTs AND\n",
    "                R4.recvTimeTs = R8.recvTimeTs AND\n",
    "                R5.recvTimeTs = R6.recvTimeTs AND\n",
    "                R5.recvTimeTs = R7.recvTimeTs AND\n",
    "                R5.recvTimeTs = R8.recvTimeTs AND\n",
    "                R6.recvTimeTs = R7.recvTimeTs AND\n",
    "                R6.recvTimeTs = R8.recvTimeTs\n",
    "            WHERE \n",
    "                R1.attrName = \"date\" AND \n",
    "                R2.attrName = \"location\" AND\n",
    "                R4.attrName = \"accx\" AND \n",
    "                R5.attrName = \"accy\" AND \n",
    "                R6.attrName = \"accz\" AND\n",
    "                R7.attrName=  \"speed\" AND\n",
    "                R8.attrName=  \"altitude\";\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define parameters for the query\n",
    "        # params = attr_name\n",
    "\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch and return the results\n",
    "        results = cursor.fetchall()\n",
    "        json_results = []\n",
    "        for row in results:\n",
    "            # json_result = process_data(row)\n",
    "            json_results.append(row)\n",
    "        return json_results\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if connection:\n",
    "            connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=fetch_data(\"AutoSenseAnalytics_IMU_Measurement_raw\", \"timestamp\",\"2025-02-09T15:55:22.000Z\",\"2025-02-09T16:31:02.000Z\")\n",
    "print(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_x=[]\n",
    "acc_y=[]\n",
    "acc_z=[]\n",
    "latitude=[]\n",
    "longitude=[]\n",
    "speed=[]\n",
    "altitude=[]\n",
    "timestamp=[]\n",
    "for i in data:\n",
    "    timestamp.append(i[0])\n",
    "    latitude.append(json.loads(i[1])['coordinates'][0])\n",
    "    longitude.append(json.loads(i[1])['coordinates'][1])\n",
    "    acc_x.append(i[2])\n",
    "    acc_y.append(i[3])\n",
    "    acc_z.append(i[4])\n",
    "    speed.append(i[5])\n",
    "    altitude.append(i[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the format '[]' to []\n",
    "acc_x_proc= [ast.literal_eval(item) for item in acc_x]\n",
    "acc_y_proc= [ast.literal_eval(item) for item in acc_y]\n",
    "acc_z_proc= [ast.literal_eval(item) for item in acc_z]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the avg for each sublist in acc_x (HERE ANY OTHER PROCESS)\n",
    "acc_x_avg=[]\n",
    "acc_y_avg=[]\n",
    "acc_z_avg=[]\n",
    "\n",
    "for i in acc_x_proc:\n",
    "    if len(i)==0:\n",
    "        acc_x_avg.append(0)\n",
    "        continue\n",
    "    acc_x_avg.append(sum(i)/len(i))\n",
    "\n",
    "for i in acc_y_proc:\n",
    "    if len(i)==0:\n",
    "        acc_y_avg.append(0)\n",
    "        continue\n",
    "    acc_y_avg.append(sum(i)/len(i))\n",
    "\n",
    "for i in acc_z_proc:\n",
    "    if len(i)==0:\n",
    "        acc_z_avg.append(0)\n",
    "        continue\n",
    "    acc_z_avg.append(sum(i)/len(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the avg of acc_x\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# Plot acc_x_avg\n",
    "axs[0].plot(timestamp[1:], acc_x_avg[1:], label='acc_x_avg', color='r')\n",
    "axs[0].set_ylabel('acc_x_avg')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot acc_y_avg\n",
    "axs[1].plot(timestamp[1:], acc_y_avg[1:], label='acc_y_avg', color='g')\n",
    "axs[1].set_ylabel('acc_y_avg')\n",
    "axs[1].legend()\n",
    "\n",
    "# Plot acc_z_avg\n",
    "axs[2].plot(timestamp[1:], acc_z_avg[1:], label='acc_z_avg', color='b')\n",
    "axs[2].set_ylabel('acc_z_avg')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.xlabel('Timestamp')\n",
    "plt.xticks([])\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(timestamp[1:], acc_x_avg[1:], label='acc_x_avg', color='r')\n",
    "plt.plot(timestamp[1:], acc_y_avg[1:], label='acc_y_avg', color='g')\n",
    "plt.plot(timestamp[1:], acc_z_avg[1:], label='acc_z_avg', color='b')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post it to influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(timestamp, latitude,longitude, acc_x_avg, acc_y_avg, acc_z_avg, speed, altitude):\n",
    "    try:\n",
    "        return {\n",
    "            'timestamp': timestamp,\n",
    "            'latitude': latitude,\n",
    "            'longitude': longitude,\n",
    "            'acc_x_avg': acc_x_avg,\n",
    "            'acc_y_avg': acc_y_avg,\n",
    "            'acc_z_avg': acc_z_avg,\n",
    "            'speed': speed,\n",
    "            'altitude': altitude\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(timestamp[1], latitude[1],longitude[1], acc_x_avg[1], acc_y_avg[1], acc_z_avg[1], speed[1], altitude[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb_client import InfluxDBClient, Point\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "# InfluxDB connection details\n",
    "influxdb_url = \"http://150.140.186.118:8086\"\n",
    "bucket = \"AutoSenseAnalytics_imu_avg\"\n",
    "org = \"students\"\n",
    "token = \"290p7cJGdKC25ZQoF2VKcL7ghuAJtX4xz50elO3B-38DBO9KxqVrI3fJQKfk9hjBU-MBKC5OMgC8hgYR4akWzw==\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points=[]\n",
    "for i in range(1,len(timestamp)):\n",
    "    point= Point(\"imu_avg\")\\\n",
    "            .field(\"acc_x_avg\", acc_x_avg[i])\\\n",
    "            .field(\"acc_y_avg\", acc_y_avg[i])\\\n",
    "            .field(\"acc_z_avg\", acc_z_avg[i])\\\n",
    "            .field(\"speed\", float(speed[i]))\\\n",
    "            .field(\"altitude\", float(altitude[i]))\\\n",
    "            .field(\"latitude\", float(latitude[i]))\\\n",
    "            .field(\"longitude\", float(longitude[i]))\\\n",
    "            .time(timestamp[i])\n",
    "    points.append(point)\n",
    "\n",
    "client = InfluxDBClient(url=influxdb_url, token=token, org=org)\n",
    "try:\n",
    "    write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "    write_api.write(bucket=bucket, org=org, record=points)\n",
    "    write_api.flush()\n",
    "finally:\n",
    "    client.close()\n",
    "    print(\"InfluxDB updated successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
